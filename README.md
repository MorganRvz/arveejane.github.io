# Statistician
I am a Statistician with a strong foundation in data analysis, statistical modeling, and academic research. Proficient in SPSS, R, and Python, with a keen eye for detail and a commitment to producing accurate, insightful results. Eager to contribute to data-driven projects and grow in a professional analytics environment.
***
### Certifications
### Education
***
# Project
This section showcases the data analytics projects that I made during my college years.
***
## Python
Title:
A Machine Learning Approach to Weather Prediction in Davao City, Philippines: Integrating K-Means Clustering and K-Nearest Neighbors (k-NN)
Objective:
  1.	To develop a k-NN model that accurately predicts relative humidity based on input variables such as visibility, temperature, pressure, and wind speed using the entire dataset.
  2.	To create groups of data points with similar characteristics using K-means clustering.
  3.	To build k-NN models for each cluster created by K-means clustering.
  4.	To compare the predictive performance of the optimal k-NN model and the cluster-based k-NN models to identify the best-performing approach.

Code for K-means Clustering integrated with K-Nearest Neighbors (k-NN): https://github.com/MorganRvz/Projects/blob/main/Clustering_withKnn.ipynb

Code for K-Nearest Neighbors (k-NN): https://github.com/MorganRvz/Projects/blob/main/Knn.ipynb

Conclusion:
Findings of the Study
This section presents the key findings derived from the application of the k-NN algorithm for humidity prediction in Davao City. The study evaluated the performance of the k-NN model when applied to the entire dataset and when combined with K-Means Clustering to create localized models. The results are discussed based on the performance metrics obtained from both approaches, providing insights into the effectiveness of k-NN and the potential improvement achieved through clustering techniques.
	k-NN model performance on the entire dataset:
The training set, the k-NN attained an RMSE of 0.029 along with the optimal k=24  and R^2 of 0.6254, indicating it explained 62.54% of the variance in the relative humidity values. While on the testing set, the k-NN achieved an RMSE of 0.02833 and an R^2 of 0.6716, indicating it explained 67.16% of the variance in the relative humidity values.
	k-NN optimal model performance for clusters 0 and 1:
For Cluster 0 on the training set, the k-NN model attained an RMSE of 0.0289 along with the optimal k=25 and R^2 of 0.3903, indicating it explained 39.03% of the variance in the relative humidity values. On the testing set for Cluster 0, the k-NN model achieved an RMSE of 0.0392 and R^2 of 0.4098, indicating it explained 40.98% of the variance in the relative humidity. For Cluster 1 on the training set, the k-NN model attained an RMSE of 0.0279 along with the optimal k=25 and R^2 of 0.4350, indicating it explained 43.50% of the variance in the relative humidity values. However, on the testing set for Cluster 1, the k-NN model attained an RMSE of 0.0280 along with the optimal k=25 and R^2 of 0.4796, indicating it explained 47.96% of the variance in the relative humidity values. The performance on the training set was notably lower than the k-NN model performance on the entire dataset.
	The k-NN model trained on the entire dataset outperformed the cluster-based models, achieving an RMSE of 0.029 and R² of 0.6254 on the training set, and slightly improving on the testing set with an RMSE of 0.02833 and R² of 0.6716, reflecting strong generalization. In contrast, the cluster-based models showed lower R² values. Cluster 0 had an RMSE of 0.0289 (R² = 0.3903) on training and 0.0392 (R² = 0.4098) on testing, while Cluster 1 had an RMSE of 0.0279 (R² = 0.4350) on training and 0.0280 (R² = 0.4796) on testing. Despite the reduced explanatory power, the cluster-based models did not exhibit overfitting, as the testing errors closely aligned with the training errors. These findings suggests that the k-NN model trained on the full dataset outperformed the hybrid approach in predicting relative humidity, both in terms of error minimization and variance explanation.


***
Classification in Python
***
Correlation and EDA
***
## R programming 
Regression Machine Learning
Classification Machine Learning 
Correlation and EDA
***
## SQL
***
## Power BI
